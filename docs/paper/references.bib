@article{qwen3omni,
  title={Qwen3-Omni Technical Report},
  author={Qwen Team},
  year={2024},
  url={https://huggingface.co/Qwen/Qwen3-Omni-30B-A3B-Instruct}
}

@article{lora,
  title={LoRA: Low-Rank Adaptation of Large Language Models},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  journal={arXiv preprint arXiv:2106.09685},
  year={2021}
}

@article{moe,
  title={Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer},
  author={Shazeer, Noam and Mirhoseini, Azalia and Maziarz, Krzysztof and Davis, Andy and Le, Quoc and Hinton, Geoffrey and Dean, Jeff},
  journal={arXiv preprint arXiv:1701.06538},
  year={2017}
}

@misc{mlx,
  title={MLX: Efficient Machine Learning on Apple Silicon},
  author={Apple},
  year={2024},
  url={https://github.com/ml-explore/mlx}
}

@misc{llamacpp,
  title={llama.cpp: Efficient LLM Inference},
  author={Gerganov, Georgi},
  year={2024},
  url={https://github.com/ggerganov/llama.cpp}
}

@article{zenai2025,
  title={Zen AI: Building Efficient AI for Everyone},
  author={Hanzo AI and Zoo Labs Foundation},
  journal={arXiv preprint},
  year={2025}
}
